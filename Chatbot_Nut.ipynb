{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chatbot_Nut.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klHTLvk4N2Uk"
      },
      "source": [
        "#Chatbot_Nut v0.2a\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7xS2WlCfS7u",
        "outputId": "c9c4c56b-1d3c-4f23-81f8-417dfbff685a"
      },
      "source": [
        "import re #Permite usar expresiones regular\n",
        "import nltk #Herramientas de lenguaje natural\n",
        "import numpy as np #Para la estructuras de datos y matrices\n",
        "import random #Herramienta para generar números pseudoaleatorios\n",
        "import json #Herramienta para el intercambio de datos y para analizar los datos\n",
        "\n",
        "import torch #Libreria para el aprendizaje automatico, utiliza los tensorflow, ejecuta el codigo de forma nativa usando la GPU\n",
        "import torch.nn as nn #Permite construir redes neuronales\n",
        "from torch.utils.data import Dataset, DataLoader #Permite indicar el conjunto de datos que que se cargará\n",
        "\n",
        "nltk.download('punkt') #Este tokenizer divide el texto en lista de oraciones."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89iJioTLUUsS"
      },
      "source": [
        "#Funciones para tokenizar (tokenize), derivar (stem) y bag_of_words (bolsa de palabras) \n",
        "from nltk.stem.porter import PorterStemmer #libreria para obtener las derivadas de las palabrasmas frecuentes\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(oraciones):\n",
        "    \"\"\"\n",
        "    dividir la oración en una matriz de palabras / fichas\n",
        "    un token puede ser una palabra o un carácter de puntuación, o un número\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(oraciones)\n",
        "\n",
        "\n",
        "def stem(palabra): #derivar\n",
        "    \"\"\"\n",
        "    derivar = encontrar la forma raíz de la palabra\n",
        "    ejemplos:\n",
        "    palabras = [\"comiamos\", \"comemos\", \"comías\"]\n",
        "    palabras = [raíz (w) para w en palabras]\n",
        "    -> [\"comer\", \"comer\", \"comer\"]\n",
        "    \"\"\"\n",
        "    return stemmer.stem(palabra.lower())\n",
        "\n",
        "\n",
        "def bag_of_words(tokenized_sentence, palabras):\n",
        "    \"\"\"\n",
        "    bolsa de devolución de matriz de palabras:\n",
        "     1 por cada palabra conocida que existe en la oración, 0 en caso contrario\n",
        "     ejemplo:\n",
        "     frase = [\"hola\", \"cómo\", \"estas\", \"tú\"]\n",
        "     palabras =                   [\"hola\", \"hola\", \"yo\", \"tú\", \"adiós\", \"gracias\", \"genial\"]\n",
        "     palabras de entrenamiento =  [  0   ,    1  ,  0  ,  1  ,    0   ,    0     ,    0    ]\n",
        "    \"\"\"\n",
        "    # derivar cada palabra\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    # inicializar bolsa con 0 para cada palabra\n",
        "    bag = np.zeros(len(palabras), dtype=np.float32)\n",
        "    for idx, w in enumerate(palabras):\n",
        "        if w in sentence_words: \n",
        "            bag[idx] = 1\n",
        "\n",
        "    return bag"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXm4aLzhVH3F"
      },
      "source": [
        "#función para nuestro modelo de RNN\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, tamanio_de_entrada, tamanio_oculto, numero_de_clases):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(tamanio_de_entrada, tamanio_oculto) \n",
        "        self.l2 = nn.Linear(tamanio_oculto, tamanio_oculto) \n",
        "        self.l3 = nn.Linear(tamanio_oculto, numero_de_clases)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # sin activación y sin softmax al final\n",
        "        return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOnC7rQuN5Ul",
        "outputId": "f9ce6871-4990-44bb-8199-f563531f14a3"
      },
      "source": [
        "#cargamos nuestra bd\n",
        "with open('basededatosNut.json', 'r') as f:\n",
        "    dietas = json.load(f)\n",
        "\n",
        "lista_de_palabras = []\n",
        "etiquetas = []\n",
        "xy = []\n",
        "#iterar cada oración de nuestro patron de dietas\n",
        "for diet in dietas['dietas']:\n",
        "    etiqueta = diet['etiqueta'] \n",
        "    etiquetas.append(etiqueta) #agregar a la lista de etiquetas\n",
        "    for patron in diet['patrones']:\n",
        "        # tokenizar cada palabra de la oración\n",
        "        w = tokenize(patron)\n",
        "        # agregar a nuestra lista de palabras\n",
        "        lista_de_palabras.extend(w)\n",
        "        # agregar al par xy\n",
        "        xy.append((w, etiqueta))\n",
        "\n",
        "# ignorar palabra\n",
        "ignorar_signos = ['?', '.', '!']\n",
        "#convierte minuscula e ignora signos\n",
        "lista_de_palabras = [stem(w) for w in lista_de_palabras if w not in ignorar_signos]\n",
        "# eliminar duplicados y ordenar\n",
        "lista_de_palabras = sorted(set(lista_de_palabras))\n",
        "etiquetas = sorted(set(etiquetas))\n",
        "\n",
        "print(len(xy), \"patrones\")\n",
        "print(len(etiquetas), \"etiquetas:\", etiquetas)\n",
        "print(len(lista_de_palabras), \"palabras derivadas unicas:\", lista_de_palabras)\n",
        "\n",
        "# crear datos de entrenamiento\n",
        "X_cola = []\n",
        "Y_cola = []\n",
        "for (patron_de_oracion, etiqueta) in xy:\n",
        "    # X: bolsa de palabras para cada patron de sentencia\n",
        "    bolsa = bag_of_words(patron_de_oracion, lista_de_palabras)\n",
        "    X_cola.append(bolsa)\n",
        "    # y: PyTorch CrossEntropyLoss solo necesita etiquetas de clase, no one-hot\n",
        "    ETIQUETA_ = etiquetas.index(etiqueta)\n",
        "    Y_cola.append(ETIQUETA_)\n",
        "\n",
        "X_cola = np.array(X_cola)\n",
        "Y_cola = np.array(Y_cola)\n",
        "\n",
        "# Hiperparámetros para RNN\n",
        "interaciones = 1000 #NUMERO DE INTERACIONES\n",
        "batch_size = 8      #tamanio de lote\n",
        "tasa_de_aprendizaje = 0.001\n",
        "tamanio_de_entrada = len(X_cola[0])\n",
        "tamanio_oculto = 8\n",
        "tamanio_de_salida = len(etiquetas)\n",
        "print(tamanio_de_entrada, tamanio_de_salida)\n",
        "\n",
        "class ChatDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_cola)\n",
        "        self.x_data = X_cola\n",
        "        self.y_data = Y_cola\n",
        "\n",
        "    # Admite la indexación de modo que el conjunto de datos [i] se pueda utilizar para obtener la i-ésima muestra\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # podemos llamar a len (conjunto de datos) para devolver el tamaño\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "dataset = ChatDataset()\n",
        "cargador_de_cola = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "dispositivo = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "modelo = NeuralNet(tamanio_de_entrada, tamanio_oculto, tamanio_de_salida).to(dispositivo)\n",
        "\n",
        "# Pérdida y optimizacion\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "optimizador = torch.optim.Adam(modelo.parameters(), lr=tasa_de_aprendizaje)\n",
        "\n",
        "# Entrena el modelo\n",
        "for nivel in range(interaciones):\n",
        "    for (PALABRAS, ETIQUETAS) in cargador_de_cola:\n",
        "        PALABRAS = PALABRAS.to(dispositivo)\n",
        "        ETIQUETAS = ETIQUETAS.to(dtype=torch.long).to(dispositivo)\n",
        "        \n",
        "        # Pase adelantado\n",
        "        SALIDAS = modelo(PALABRAS)\n",
        "        # si y sería one-hot, debemos aplicar\n",
        "        # etiquetas = antorcha.max (etiquetas, 1) [1]\n",
        "        PERDIDAS = criterio(SALIDAS, ETIQUETAS)\n",
        "        \n",
        "        # Retroceder y optimizar\n",
        "        optimizador.zero_grad()\n",
        "        PERDIDAS.backward()\n",
        "        optimizador.step()\n",
        "        \n",
        "    if (nivel+1) % 100 == 0:\n",
        "        print (f'interaciones [{nivel+1}/{interaciones}], perdidos: {PERDIDAS.item():.4f}')\n",
        "\n",
        "\n",
        "print(f'perdida final: {PERDIDAS.item():.4f}')\n",
        "\n",
        "datos = {\n",
        "\"estado_del_modelo\": modelo.state_dict(),\n",
        "\"tamanio_de_entrada\": tamanio_de_entrada,\n",
        "\"tamanio_oculto\": tamanio_oculto,\n",
        "\"tamanio_de_salida\": tamanio_de_salida,\n",
        "\"lista_de_palabras\": lista_de_palabras,\n",
        "\"etiquetas\": etiquetas\n",
        "}\n",
        "\n",
        "FILE = \"datos.pth\"\n",
        "torch.save(datos, FILE)\n",
        "\n",
        "print(f'Entrenamiento completado, archivo guardado en: {FILE}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88 patrones\n",
            "16 etiquetas: ['Comer', 'Dietasadulto', 'Dietasniño', 'IMC', 'TiposdeFrutas', 'Tiposdealimentos', 'adios', 'dietaenfermedades', 'dietas', 'edad', 'estado', 'gracias', 'peso', 'saludo', 'talla', 'tipo']\n",
            "107 palabras derivadas unicas: ['1,80', '1,80m', '1.20', '1.50', '1.75', '1.80', '1.80m', '10', '20', '30', '50kg', '60', '60kg', '65k', '68k', '68kg', '70', '70k', '70kg', 'adió', 'adulto', 'ahí', 'algo', 'alguien', 'alrededor', 'año', 'bajar', 'bien', 'buen', 'bye', 'calculo', 'cansado', 'cardiovascular', 'clasificacion', 'cocinar', 'coma', 'comer', 'crecer', 'cómo', 'dame', 'de', 'deportista', 'dieta', 'dime', 'dulc', 'día', 'el', 'enfermedad', 'es', 'eso', 'estoy', 'está', 'evitar', 'excelent', 'favor', 'fruta', 'gana', 'gracia', 'hambr', 'hasta', 'hello', 'hola', 'holi', 'hoy', 'imc', 'kg', 'luego', 'm', 'mal', 'mayor', 'mi', 'mido', 'mucha', 'muy', 'neutra', 'niño', 'no', 'nut', 'oye', 'para', 'pero', 'peso', 'por', 'problema', 'puedo', 'que', 'quiero', 'resfrio', 'rico', 'sayonara', 'segun', 'según', 'semiácida', 'soy', 'sugier', 'talla', 'tengo', 'tengp', 'tien', 'tipo', 'un', 'una', 'visual', '¡mucha', '¿hay', 'ácida', 'útil']\n",
            "107 16\n",
            "interaciones [100/1000], perdidos: 0.1616\n",
            "interaciones [200/1000], perdidos: 0.0169\n",
            "interaciones [300/1000], perdidos: 0.0028\n",
            "interaciones [400/1000], perdidos: 0.0013\n",
            "interaciones [500/1000], perdidos: 0.0005\n",
            "interaciones [600/1000], perdidos: 0.0003\n",
            "interaciones [700/1000], perdidos: 0.0001\n",
            "interaciones [800/1000], perdidos: 0.0001\n",
            "interaciones [900/1000], perdidos: 0.0001\n",
            "interaciones [1000/1000], perdidos: 0.0000\n",
            "perdida final: 0.0000\n",
            "Entrenamiento completado, archivo guardado en: datos.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fJlKEjzN-z0",
        "outputId": "3d1ee17e-696f-437f-a39c-e9ac1aed68f4"
      },
      "source": [
        "#Declaramos el objeto torch\n",
        "dispositivo = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Cargamos nuestra bd\n",
        "with open('basededatosNut.json', 'r') as json_data:\n",
        "    DIETAS = json.load(json_data)\n",
        "\n",
        "#Cargamos los datos de entrenamiento\n",
        "FILE = \"datos.pth\"\n",
        "datos = torch.load(FILE)\n",
        "\n",
        "#Obtenemos los parámetros\n",
        "_tamanio_entrada = datos[\"tamanio_de_entrada\"]\n",
        "_tamanio_oculto = datos[\"tamanio_oculto\"]\n",
        "_tamanio_salida = datos[\"tamanio_de_salida\"]\n",
        "_lista_de_palabras = datos['lista_de_palabras']\n",
        "_etiqueta = datos['etiquetas']\n",
        "_estado_modelo = datos[\"estado_del_modelo\"]\n",
        "\n",
        "#Crea el modelo de reconocimiento\n",
        "MODELO = NeuralNet(_tamanio_entrada, _tamanio_oculto, _tamanio_salida).to(dispositivo)\n",
        "MODELO.load_state_dict(_estado_modelo)\n",
        "MODELO.eval() #evalua las respuestas\n",
        "\n",
        "\n",
        "bot_name = \"BotNut\"\n",
        "print(f\"{bot_name}: Mi nombre es BotNut. Responderé a tus consultas, si desea salir, escriba adios\")\n",
        "while True:\n",
        "    sentencias = input(\"Tu: \")\n",
        "    if sentencias == \"adios\":\n",
        "        print(f\"{bot_name}:Que tengas un excelente día\")\n",
        "        break\n",
        "\n",
        "    sentencias = tokenize(sentencias) #Tokenizamos las palabras\n",
        "    X = bag_of_words(sentencias, _lista_de_palabras) #Coincidencia de palabras con la bd json\n",
        "    X = X.reshape(1, X.shape[0]) \n",
        "    X = torch.from_numpy(X).to(dispositivo) #Objeto de entrenamiento y posibles respuestas\n",
        "\n",
        "    salida = MODELO(X) \n",
        "    _, prediccion = torch.max(salida, dim=1)\n",
        "\n",
        "    ETIQUETA = _etiqueta[prediccion.item()] #Etiquetas y predicciones\n",
        "\n",
        "    problemas = torch.softmax(salida, dim=1) #Entrada de n dimensiones y rescalado de salidas de n dimensiones\n",
        "    probabilidad = problemas[0][prediccion.item()] #Prediccion de la respuesta mas acertada\n",
        "    if probabilidad.item() > 0.75: #Probabilidades mayores a 75%\n",
        "        for diets in DIETAS['dietas']: #Posibles dietas\n",
        "            if ETIQUETA == diets[\"etiqueta\"]:\n",
        "                print(f\"{bot_name}: {random.choice(diets['respuestas'])}\")\n",
        "    else:\n",
        "        print(f\"{bot_name}: No entiendo...\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BotNut: Mi nombre es BotNut. Responderé a tus consultas, si desea salir, escriba adios\n",
            "Tu: hola\n",
            "BotNut: Hello I'm Nut, espero tengas un buen dia\n",
            "Tu: adios\n",
            "BotNut:Que tengas un excelente día\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}